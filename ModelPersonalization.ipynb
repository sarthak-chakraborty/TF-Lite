{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelPersonalization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthak-chakraborty/TF-Lite/blob/master/ModelPersonalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lftwhaRMfGng",
        "colab_type": "text"
      },
      "source": [
        "### Note:\n",
        "- After every execution of the tflite convert code and saving it in `custom_keras_model` directory, restart the kernel and execute the required cell.\n",
        "\n",
        "- The whitelisted operators supported by tflite convert is given in [this link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/flex/whitelisted_flex_ops.cc)\n",
        "\n",
        "- Link for the materials: [https://github.com/tensorflow/examples/tree/master/lite/examples/model_personalization](https://github.com/tensorflow/examples/tree/master/lite/examples/model_personalization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKsFTU8sl3lD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62d14283-688d-41cd-f3a6-21c74f93e8a9"
      },
      "source": [
        "# Clone the github repo\n",
        "!git clone https://github.com/sarthak-chakraborty/examples.git #(Contains changes)\n",
        "\n",
        "# Actual Repo\n",
        "# !git clone https://github.com/tensorflow/examples.git\n",
        "\n",
        "%cd examples/lite/examples/model_personalization/converter\n",
        "!pip install -e ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'examples'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10675 (delta 0), reused 0 (delta 0), pack-reused 10666\u001b[K\n",
            "Receiving objects: 100% (10675/10675), 19.30 MiB | 32.30 MiB/s, done.\n",
            "Resolving deltas: 100% (5475/5475), done.\n",
            "/content/examples/lite/examples/model_personalization/converter\n",
            "Obtaining file:///content/examples/lite/examples/model_personalization/converter\n",
            "Collecting tensorflow==2.0.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/4b/77f0965ec7e8a76d3dcd6a22ca8bbd2b934cd92c4ded43fef6bea5ff3258/tensorflow-2.0.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 70kB/s \n",
            "\u001b[?25hCollecting Pillow<7.0,>=6.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<2.0,>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from tfltransfer==0.1) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (1.29.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (3.10.0)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (3.2.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (0.2.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc0->tfltransfer==0.1) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0rc0->tfltransfer==0.1) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0rc0->tfltransfer==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0rc0->tfltransfer==0.1) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0rc0->tfltransfer==0.1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0rc0->tfltransfer==0.1) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0rc0->tfltransfer==0.1) (3.1.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow, Pillow, tfltransfer\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Running setup.py develop for tfltransfer\n",
            "Successfully installed Pillow-6.2.2 tb-nightly-1.15.0a20190806 tensorflow-2.0.0rc0 tf-estimator-nightly-1.14.0.dev2019080601 tfltransfer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIMZ6TcgBub6",
        "colab_type": "text"
      },
      "source": [
        "1. Simple CNN Model Conversion to TFLite. All the operations have thir Ops defined in whitelisted_flex_ops.cc file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab1JSpYkmzIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "649a50a0-53ee-44b0-c509-4073ca1ad45d"
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tfltransfer import bases\n",
        "from tfltransfer import heads\n",
        "from tfltransfer import optimizers\n",
        "from tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\n",
        "\n",
        "\"\"\"\n",
        "Get the Base model\n",
        "\"\"\"\n",
        "base = tf.keras.Sequential([tf.keras.layers.InputLayer(input_shape=(224,224,3))])\n",
        "base.save(\"base_model\", save_format=\"tf\")\n",
        "base = bases.SavedModelBase(\"base_model\")\n",
        "\n",
        "\"\"\"\n",
        "Simple Head Model with only Conv2D and MaxPool2D layers\n",
        "\"\"\"\n",
        "head = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, 3, input_shape=(224, 224, 3), padding='same'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(4, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Optimizer is ignored by the converter! See docs.\n",
        "head.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
        "converter = TFLiteTransferConverter(4,\n",
        "                                    base,\n",
        "                                    heads.KerasModelHead(head),\n",
        "                                    optimizers.SGD(3e-2),\n",
        "                                    train_batch_size=20)\n",
        "\n",
        "converter.convert_and_save('custom_keras_model')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f335a9ee9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f335a9ee9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f335a17ab70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f335a17ab70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f335a174400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f335a174400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f33559232f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f33559232f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f33550f7d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f33550f7d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Assets written to: base_model/assets\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:44: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /tmp/tmpazzl3p1ptflite-transfer-keras-model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:49: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpazzl3p1ptflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpazzl3p1ptflite-transfer-keras-model/variables/variables\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpazzl3p1ptflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:275: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 10 variables.\n",
            "INFO:tensorflow:Converted 10 variables to const ops.\n",
            "WARNING:tensorflow:Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f33559231e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f33559231e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f335a17a400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f335a17a400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py:854: UserWarning: Property target_ops is deprecated, please use target_spec.supported_ops instead.\n",
            "  \"target_spec.supported_ops instead.\" % name)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEt0Miu2dkYf",
        "colab_type": "text"
      },
      "source": [
        "2. Next, we try to convert a shortened version of MobileNet to TFLite. Note that here, we use `DepthwiseConv2d` layer for which the Ops is not defined in whitelisted_flex_ops.cc.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rPVoDpsnm_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ed84f9c-bc80-4768-e66f-67a20a326423"
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tfltransfer import bases\n",
        "from tfltransfer import heads\n",
        "from tfltransfer import optimizers\n",
        "from tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\n",
        "\n",
        "\"\"\"\n",
        "Get the Base model\n",
        "\"\"\"\n",
        "base = tf.keras.Sequential([tf.keras.layers.InputLayer(input_shape=(224,224,3))])\n",
        "base.save(\"base_model\", save_format=\"tf\")\n",
        "base = bases.SavedModelBase(\"base_model\")\n",
        "\n",
        "\"\"\"\n",
        "Mobile Net without BatchNorm\n",
        "\"\"\"\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=(3,3), strides=(1,1), input_shape=(224, 224, 3), padding='same', name='input_conv32'))\n",
        "model.add(layers.Activation('relu', name='input_act'))\n",
        "\n",
        "# (Channels, Strides)\n",
        "int_layers = [\n",
        "  (64, (1, 1)),\n",
        "  (128, (2, 2))\n",
        "  # (128, (1, 1)),\n",
        "  # (256, (2, 2)),\n",
        "  # (256, (1, 1)),\n",
        "  # (512, (2, 2)),\n",
        "  # *[(512, (1, 1)) for _ in range(5)],\n",
        "  # (1024, (2, 2)),\n",
        "  # (1024, (1, 1))\n",
        "]\n",
        "i=1\n",
        "for channels, strides in int_layers:\n",
        "  # Depthwise\n",
        "  model.add(layers.DepthwiseConv2D(kernel_size=(3, 3), strides=strides, use_bias=False, padding='same', name='depth_conv{}_{}'.format(channels, i)))\n",
        "  model.add(layers.Activation('relu', name='depth_act_{}'.format(i)))\n",
        "\n",
        "  # Pointwise\n",
        "  model.add(layers.Conv2D(channels, kernel_size=(1, 1), strides=(1, 1), use_bias=False, padding='valid', name='point_conv{}_{}'.format(channels, i)))\n",
        "  model.add(layers.Activation('relu', name='point_act_{}'.format(i)))\n",
        "\n",
        "  i += 1\n",
        "\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "\n",
        "head = model\n",
        "\n",
        "# Optimizer is ignored by the converter! See docs.\n",
        "head.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
        "converter = TFLiteTransferConverter(4,\n",
        "                                    base,\n",
        "                                    heads.KerasModelHead(head),\n",
        "                                    optimizers.SGD(3e-2),\n",
        "                                    train_batch_size=20)\n",
        "\n",
        "converter.convert_and_save('custom_keras_model')\n",
        "\n",
        "\"\"\"\n",
        "On adding the line `converter.allow_custom_ops=True` at the desired location, it will get converted, since the converter expects that a custom operation is there\n",
        "\n",
        "While training on android device the following error shows up:\n",
        "\n",
        "Caused by: java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: Encountered unresolved custom op: DepthwiseConv2dNativeBackpropInput.\n",
        "  Node number 146 (DepthwiseConv2dNativeBackpropInput) failed to prepare.\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a1b192488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a1b192488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a169701e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a169701e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a1610d598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a1610d598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a169709d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a169709d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a160e8840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a160e8840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Assets written to: base_model/assets\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:44: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /tmp/tmpr7pxt1ihtflite-transfer-keras-model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:49: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpr7pxt1ihtflite-transfer-keras-model/variables/variables\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpr7pxt1ihtflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpr7pxt1ihtflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:275: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 8 variables.\n",
            "INFO:tensorflow:Converted 8 variables to const ops.\n",
            "WARNING:tensorflow:Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f0a169708c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f0a169708c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a16134378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0a16134378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py:854: UserWarning: Property target_ops is deprecated, please use target_spec.supported_ops instead.\n",
            "  \"target_spec.supported_ops instead.\" % name)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-12834c7be896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                                     train_batch_size=20)\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'custom_keras_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \"\"\"\n",
            "\u001b[0;32m/content/examples/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_converter.py\u001b[0m in \u001b[0;36mconvert_and_save\u001b[0;34m(self, out_model_dir)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/examples/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_converter.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0minitialize_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_initialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mbottleneck_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_bottleneck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mtrain_head_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_train_head_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0minference_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_inference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mparameter_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_parameter_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_model_lite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/examples/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_converter.py\u001b[0m in \u001b[0;36m_generate_train_head_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_requires_flex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpsSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSELECT_TF_OPS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_generate_inference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m           \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m           \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m           **converter_kwargs)\n\u001b[0m\u001b[1;32m    984\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m       result = _toco_convert_graph_def(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    450\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConverterError\u001b[0m: See console for info.\n2020-06-26 09:54:34.897467: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 09:54:34.897600: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NoOp\n2020-06-26 09:54:34.897629: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 09:54:34.897649: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 09:54:34.897675: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 09:54:34.897691: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 09:54:34.897706: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 09:54:34.897771: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 09:54:34.897789: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Shape\n2020-06-26 09:54:34.897811: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.897829: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.897846: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.897862: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.897878: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.897894: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.897911: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.897927: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.897952: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Slice\n2020-06-26 09:54:34.897975: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2D\n2020-06-26 09:54:34.897999: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ShapeN\n2020-06-26 09:54:34.898022: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ConcatV2\n2020-06-26 09:54:34.898042: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: BiasAdd\n2020-06-26 09:54:34.898060: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 09:54:34.898096: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 09:54:34.898116: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DepthwiseConv2dNative\n2020-06-26 09:54:34.898137: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 09:54:34.898156: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2D\n2020-06-26 09:54:34.898176: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ShapeN\n2020-06-26 09:54:34.898195: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 09:54:34.898212: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DepthwiseConv2dNative\n2020-06-26 09:54:34.898231: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 09:54:34.898247: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2D\n2020-06-26 09:54:34.898266: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ShapeN\n2020-06-26 09:54:34.898285: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 09:54:34.898302: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mean\n2020-06-26 09:54:34.898321: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MatMul\n2020-06-26 09:54:34.898340: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: BiasAdd\n2020-06-26 09:54:34.898357: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Shape\n2020-06-26 09:54:34.898374: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Shape\n2020-06-26 09:54:34.898391: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Slice\n2020-06-26 09:54:34.898408: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Slice\n2020-06-26 09:54:34.898426: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ConcatV2\n2020-06-26 09:54:34.898443: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 09:54:34.898465: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: SoftmaxCrossEntropyWithLogits\n2020-06-26 09:54:34.898484: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 09:54:34.898519: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Shape\n2020-06-26 09:54:34.898536: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Fill\n2020-06-26 09:54:34.898571: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.898587: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mul\n2020-06-26 09:54:34.898605: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Sum\n2020-06-26 09:54:34.898623: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\n2020-06-26 09:54:34.898640: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.898657: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Cast\n2020-06-26 09:54:34.898675: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DivNoNan\n2020-06-26 09:54:34.898693: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DivNoNan\n2020-06-26 09:54:34.898709: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.898725: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.898747: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.898764: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.898780: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.898796: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 09:54:34.898813: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Tile\n2020-06-26 09:54:34.898841: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mul\n2020-06-26 09:54:34.898857: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.898872: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ExpandDims\n2020-06-26 09:54:34.898890: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mul\n2020-06-26 09:54:34.898946: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 09:54:34.898966: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: BiasAddGrad\n2020-06-26 09:54:34.898980: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MatMul\n2020-06-26 09:54:34.898996: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MatMul\n2020-06-26 09:54:34.899008: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 09:54:34.899041: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Tile\n2020-06-26 09:54:34.899059: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mul\n2020-06-26 09:54:34.899086: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 09:54:34.899106: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropInput\n2020-06-26 09:54:34.899148: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropFilter\n2020-06-26 09:54:34.899169: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 09:54:34.899187: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DepthwiseConv2dNativeBackpropInput\n2020-06-26 09:54:34.899212: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DepthwiseConv2dNativeBackpropFilter\n2020-06-26 09:54:34.899232: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 09:54:34.899249: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropInput\n2020-06-26 09:54:34.899270: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropFilter\n2020-06-26 09:54:34.899290: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 09:54:34.899307: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DepthwiseConv2dNativeBackpropInput\n2020-06-26 09:54:34.899327: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DepthwiseConv2dNativeBackpropFilter\n2020-06-26 09:54:34.899347: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 09:54:34.899363: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: BiasAddGrad\n2020-06-26 09:54:34.899382: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropFilter\n2020-06-26 09:54:34.899998: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 88 operators, 125 arrays (0 quantized)\n2020-06-26 09:54:34.900598: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 80 operators, 118 arrays (0 quantized)\n2020-06-26 09:54:34.901349: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 80 operators, 118 arrays (0 quantized)\n2020-06-26 09:54:34.901978: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 80 operators, 118 arrays (0 quantized)\n2020-06-26 09:54:34.902737: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 80 operators, 118 arrays (0 quantized)\n2020-06-26 09:54:34.903263: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 80 operators, 118 arrays (0 quantized)\n2020-06-26 09:54:34.903906: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.\n2020-06-26 09:54:34.904126: I tensorflow/lite/toco/toco_tooling.cc:436] Estimated count of arithmetic ops: 0 billion (note that a multiply-add is counted as 2 ops).\n2020-06-26 09:54:34.904450: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropInput is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 09:54:34.904469: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropFilter is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 09:54:34.904483: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropInput is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 09:54:34.904500: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropFilter is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 09:54:34.904630: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropInput is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 09:54:34.904644: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropFilter is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 09:54:34.904657: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropInput is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 09:54:34.904670: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropFilter is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 09:54:34.904733: E tensorflow/lite/toco/toco_tooling.cc:466] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: . Here is a list of operators for which you will need custom implementations: DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropInput.\nTraceback (most recent call last):\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89, in main\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52, in execute\n    enable_mlir_converter)\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: . Here is a list of operators for which you will need custom implementations: DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropInput.\n\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDG46ESzJhuu",
        "colab_type": "text"
      },
      "source": [
        "3a. One way to mitigate this is to replace DepthwiseConv2D layer into a combination of Conv2D layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1AU5fEqJi_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fb8afb0-fe5b-45af-fde2-7cdc93ec3aa9"
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tfltransfer import bases\n",
        "from tfltransfer import heads\n",
        "from tfltransfer import optimizers\n",
        "from tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\n",
        "\n",
        "\"\"\"\n",
        "Get the Base model\n",
        "\"\"\"\n",
        "base = tf.keras.Sequential([tf.keras.layers.InputLayer(input_shape=(32,32,3))])\n",
        "base.save(\"base_model\", save_format=\"tf\")\n",
        "base = bases.SavedModelBase(\"base_model\")\n",
        "\n",
        "\"\"\"\n",
        "Mobile Net without BatchNorm\n",
        "\"\"\"\n",
        "x_in = tf.keras.Input(shape=(32,32,3))\n",
        "x = layers.Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', name='input_conv32')(x_in)\n",
        "x = layers.Activation('relu', name='input_act')(x)\n",
        "\n",
        "prev_channels = 32\n",
        "# (Channels, Strides)\n",
        "int_layers = [\n",
        "  (64, (1, 1))\n",
        "#   (128, (2, 2)),\n",
        "#   (128, (1, 1)),\n",
        "#   (256, (2, 2)),\n",
        "#   (256, (1, 1)),\n",
        "#   (512, (2, 2)),\n",
        "#   *[(512, (1, 1)) for _ in range(5)],\n",
        "#   (1024, (2, 2)),\n",
        "#   (1024, (1, 1))\n",
        "]\n",
        "# int_layers=[(64, (1,1))]\n",
        "i=1\n",
        "for channels, strides in int_layers:\n",
        "  # Depthwise\n",
        "  x_depth = []\n",
        "  print(i)\n",
        "  for channel_num in range(prev_channels):\n",
        "    sliced_tensor = x[:, :, :, channel_num]\n",
        "    tensor = tf.expand_dims(sliced_tensor, axis=3)\n",
        "    x_dummy = layers.Conv2D(1, kernel_size=(3,3), strides=strides, use_bias=False, padding='same', name='depth_conv{}-{}_{}'.format(channels, channel_num, i))(tensor)\n",
        "    x_depth.append(x_dummy)\n",
        "  x = tf.stack([x_depth[j][:, :, :, 0] for j in range(prev_channels)], axis=3)\n",
        "  x = layers.Activation('relu', name='depth_act_{}'.format(i))(x)\n",
        "\n",
        "  # Pointwise\n",
        "  x = layers.Conv2D(channels, kernel_size=(1, 1), strides=(1, 1), use_bias=False, padding='valid', name='point_conv{}_{}'.format(channels, i))(x)\n",
        "  x = layers.Activation('relu', name='point_act_{}'.format(i))(x)\n",
        "\n",
        "  prev_channels = channels\n",
        "  i += 1\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x_out = layers.Dense(10, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs=x_in, outputs=x_out)\n",
        "\n",
        "\n",
        "head = model\n",
        "\n",
        "# Optimizer is ignored by the converter! See docs.\n",
        "head.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
        "converter = TFLiteTransferConverter(10,\n",
        "                                    base,\n",
        "                                    heads.KerasModelHead(head),\n",
        "                                    optimizers.SGD(3e-2),\n",
        "                                    train_batch_size=4)\n",
        "\n",
        "converter.convert_and_save('custom_keras_model')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51c2116488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51c2116488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51c20fa620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51c20fa620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51bd09e598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51bd09e598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f51c20fad90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f51c20fad90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51bd06d840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51bd06d840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Assets written to: base_model/assets\n",
            "1\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:44: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /tmp/tmpbdpvgowztflite-transfer-keras-model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:49: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpbdpvgowztflite-transfer-keras-model/variables/variables\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpbdpvgowztflite-transfer-keras-model/variables/variables\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpbdpvgowztflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:275: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 37 variables.\n",
            "INFO:tensorflow:Converted 37 variables to const ops.\n",
            "WARNING:tensorflow:Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f51b8cd07b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f51b8cd07b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51b8cd0378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f51b8cd0378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py:854: UserWarning: Property target_ops is deprecated, please use target_spec.supported_ops instead.\n",
            "  \"target_spec.supported_ops instead.\" % name)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuKq3snLNnNR",
        "colab_type": "text"
      },
      "source": [
        "3b. The other way is to freeze the particular layer. Here we change the model description while keeping a DepthwiseConv2D in the model definition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDr9P9SKNnrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76297cb3-2fe6-406b-bec1-409ff52d085d"
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, MaxPool2D, BatchNormalization, Flatten, Dropout, Dense, Activation, ReLU, Add, Concatenate, InputSpec\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tfltransfer import bases\n",
        "from tfltransfer import heads\n",
        "from tfltransfer import optimizers\n",
        "from tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\n",
        "\n",
        "\"\"\"\n",
        "Get the Base model\n",
        "\"\"\"\n",
        "base = tf.keras.Sequential([tf.keras.layers.InputLayer(input_shape=(224,224,3))])\n",
        "base.save(\"base_model\", save_format=\"tf\")\n",
        "base = bases.SavedModelBase(\"base_model\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Head Model\n",
        "\"\"\"\n",
        "x_in = Input(shape=(224,224,3), name='input')\n",
        "x = Conv2D(32, kernel_size=(3, 3), padding='valid', use_bias=False, name='conv32_1')(x_in)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(32, kernel_size=(3,3), padding='same', use_bias=False, name='conv32_2')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = Conv2D(64, kernel_size=(3, 3), padding='valid', use_bias=False, name='conv64_1')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = DepthwiseConv2D(kernel_size=(3,3), strides=(2,2), padding='same', use_bias=False, name='depthwise_conv_1')(x)\n",
        "x = Conv2D(64, kernel_size=(1, 1), padding='valid', use_bias=False, name='pointwise_conv64_1')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x_out = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=x_in, outputs=x_out, name='my_model')\n",
        "\n",
        "\n",
        "# Here 7th layer is the DepthwiseConv2D layer\n",
        "model.layers[7].trainable = False\n",
        "\n",
        "\n",
        "for variable in model.trainable_variables:\n",
        "    print(variable.name)\n",
        "\n",
        "head = model\n",
        "\n",
        "# Optimizer is ignored by the converter! See docs.\n",
        "head.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
        "converter = TFLiteTransferConverter(4,\n",
        "                                    base,\n",
        "                                    heads.KerasModelHead(head),\n",
        "                                    optimizers.SGD(3e-2),\n",
        "                                    train_batch_size=20)\n",
        "\n",
        "converter.convert_and_save('custom_keras_model')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b7495510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b7495510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b2415e18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b2415e18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b23d82f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b23d82f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fc3b2411bf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fc3b2411bf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b1ba48c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b1ba48c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Assets written to: base_model/assets\n",
            "conv32_1/kernel:0\n",
            "conv32_2/kernel:0\n",
            "conv64_1/kernel:0\n",
            "pointwise_conv64_1/kernel:0\n",
            "dense/kernel:0\n",
            "dense/bias:0\n",
            "dense_1/kernel:0\n",
            "dense_1/bias:0\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:44: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /tmp/tmpqn8_9c_5tflite-transfer-keras-model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:49: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpqn8_9c_5tflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpqn8_9c_5tflite-transfer-keras-model/variables/variables\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpqn8_9c_5tflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:275: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 9 variables.\n",
            "INFO:tensorflow:Converted 9 variables to const ops.\n",
            "WARNING:tensorflow:Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7fc3b78b7b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7fc3b78b7b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b23d88c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc3b23d88c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py:854: UserWarning: Property target_ops is deprecated, please use target_spec.supported_ops instead.\n",
            "  \"target_spec.supported_ops instead.\" % name)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-57962bf8171f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m                                     train_batch_size=20)\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'custom_keras_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/examples/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_converter.py\u001b[0m in \u001b[0;36mconvert_and_save\u001b[0;34m(self, out_model_dir)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/examples/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_converter.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0minitialize_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_initialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mbottleneck_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_bottleneck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mtrain_head_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_train_head_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0minference_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_inference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mparameter_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_parameter_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_model_lite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/examples/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_converter.py\u001b[0m in \u001b[0;36m_generate_train_head_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_requires_flex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpsSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSELECT_TF_OPS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_generate_inference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m           \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m           \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m           **converter_kwargs)\n\u001b[0m\u001b[1;32m    984\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m       result = _toco_convert_graph_def(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    450\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConverterError\u001b[0m: See console for info.\n2020-06-26 10:47:47.514171: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 10:47:47.514340: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NoOp\n2020-06-26 10:47:47.514373: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 10:47:47.514394: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 10:47:47.514418: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 10:47:47.514437: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 10:47:47.514456: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 10:47:47.514503: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Const\n2020-06-26 10:47:47.514522: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Shape\n2020-06-26 10:47:47.514538: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.514556: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.514572: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.514590: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.514606: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.514621: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.514637: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.514653: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.514669: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.514695: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Slice\n2020-06-26 10:47:47.514719: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2D\n2020-06-26 10:47:47.514743: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ShapeN\n2020-06-26 10:47:47.514766: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ConcatV2\n2020-06-26 10:47:47.514785: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 10:47:47.514803: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 10:47:47.514823: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2D\n2020-06-26 10:47:47.514843: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ShapeN\n2020-06-26 10:47:47.514860: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 10:47:47.514880: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2D\n2020-06-26 10:47:47.514900: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ShapeN\n2020-06-26 10:47:47.514918: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 10:47:47.514936: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DepthwiseConv2dNative\n2020-06-26 10:47:47.514958: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2D\n2020-06-26 10:47:47.514978: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ShapeN\n2020-06-26 10:47:47.514997: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 10:47:47.515013: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515030: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 10:47:47.515047: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MatMul\n2020-06-26 10:47:47.515073: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: BiasAdd\n2020-06-26 10:47:47.515092: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Relu\n2020-06-26 10:47:47.515108: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515125: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MatMul\n2020-06-26 10:47:47.515142: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: BiasAdd\n2020-06-26 10:47:47.515159: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Shape\n2020-06-26 10:47:47.515177: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Shape\n2020-06-26 10:47:47.515194: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Slice\n2020-06-26 10:47:47.515212: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Slice\n2020-06-26 10:47:47.515230: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ConcatV2\n2020-06-26 10:47:47.515260: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 10:47:47.515277: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: SoftmaxCrossEntropyWithLogits\n2020-06-26 10:47:47.515297: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 10:47:47.515315: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Shape\n2020-06-26 10:47:47.515332: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Fill\n2020-06-26 10:47:47.515350: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515367: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mul\n2020-06-26 10:47:47.515385: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Sum\n2020-06-26 10:47:47.515404: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\n2020-06-26 10:47:47.515422: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515456: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Cast\n2020-06-26 10:47:47.515476: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DivNoNan\n2020-06-26 10:47:47.515493: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DivNoNan\n2020-06-26 10:47:47.515510: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515527: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515546: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515564: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515578: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515596: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 10:47:47.515613: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Tile\n2020-06-26 10:47:47.515631: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mul\n2020-06-26 10:47:47.515648: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515665: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ExpandDims\n2020-06-26 10:47:47.515683: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mul\n2020-06-26 10:47:47.515696: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Identity\n2020-06-26 10:47:47.515710: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: BiasAddGrad\n2020-06-26 10:47:47.515729: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MatMul\n2020-06-26 10:47:47.515748: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MatMul\n2020-06-26 10:47:47.515765: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 10:47:47.515791: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: BiasAddGrad\n2020-06-26 10:47:47.515809: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MatMul\n2020-06-26 10:47:47.515827: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MatMul\n2020-06-26 10:47:47.515845: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Reshape\n2020-06-26 10:47:47.515862: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 10:47:47.515882: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropInput\n2020-06-26 10:47:47.515908: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropFilter\n2020-06-26 10:47:47.515931: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DepthwiseConv2dNativeBackpropInput\n2020-06-26 10:47:47.515952: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 10:47:47.515972: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropInput\n2020-06-26 10:47:47.515995: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropFilter\n2020-06-26 10:47:47.516016: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 10:47:47.516036: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropInput\n2020-06-26 10:47:47.516067: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropFilter\n2020-06-26 10:47:47.516088: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReluGrad\n2020-06-26 10:47:47.516108: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Conv2DBackpropFilter\n2020-06-26 10:47:47.516761: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 92 operators, 126 arrays (0 quantized)\n2020-06-26 10:47:47.517302: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 84 operators, 119 arrays (0 quantized)\n2020-06-26 10:47:47.518017: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 84 operators, 119 arrays (0 quantized)\n2020-06-26 10:47:47.518705: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 84 operators, 119 arrays (0 quantized)\n2020-06-26 10:47:47.519530: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 84 operators, 119 arrays (0 quantized)\n2020-06-26 10:47:47.520086: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 84 operators, 119 arrays (0 quantized)\n2020-06-26 10:47:47.520778: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.\n2020-06-26 10:47:47.521001: I tensorflow/lite/toco/toco_tooling.cc:436] Estimated count of arithmetic ops: 0 billion (note that a multiply-add is counted as 2 ops).\n2020-06-26 10:47:47.521405: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropInput is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 10:47:47.521556: W tensorflow/lite/toco/tflite/operator.cc:2692] Op DepthwiseConv2dNativeBackpropInput is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-06-26 10:47:47.521833: E tensorflow/lite/toco/toco_tooling.cc:466] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: . Here is a list of operators for which you will need custom implementations: DepthwiseConv2dNativeBackpropInput.\nTraceback (most recent call last):\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89, in main\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52, in execute\n    enable_mlir_converter)\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: . Here is a list of operators for which you will need custom implementations: DepthwiseConv2dNativeBackpropInput.\n\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHiANO4XNoFl",
        "colab_type": "text"
      },
      "source": [
        "3c. Here, we will freeze all the layers that are below the DepthwiseConv2D layer, that is, all the layers from Input to DepthwiseConv2D.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0NtlzP5NofY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c97d3df9-41a0-44e4-9143-9bdc06c41b65"
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, MaxPool2D, BatchNormalization, Flatten, Dropout, Dense, Activation, ReLU, Add, Concatenate, InputSpec\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tfltransfer import bases\n",
        "from tfltransfer import heads\n",
        "from tfltransfer import optimizers\n",
        "from tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\n",
        "\n",
        "\"\"\"\n",
        "Get the Base model\n",
        "\"\"\"\n",
        "base = tf.keras.Sequential([tf.keras.layers.InputLayer(input_shape=(224,224,3))])\n",
        "base.save(\"base_model\", save_format=\"tf\")\n",
        "base = bases.SavedModelBase(\"base_model\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Head Model\n",
        "\"\"\"\n",
        "x_in = Input(shape=(224,224,3), name='input')\n",
        "x = Conv2D(32, kernel_size=(3, 3), padding='valid', use_bias=False, name='conv32_1')(x_in)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(32, kernel_size=(3,3), padding='same', use_bias=False, name='conv32_2')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = Conv2D(64, kernel_size=(3, 3), padding='valid', use_bias=False, name='conv64_1')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = DepthwiseConv2D(kernel_size=(3,3), strides=(2,2), padding='same', use_bias=False, name='depthwise_conv_1')(x)\n",
        "x = Conv2D(64, kernel_size=(1, 1), padding='valid', use_bias=False, name='pointwise_conv64_1')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x_out = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=x_in, outputs=x_out, name='my_model')\n",
        "\n",
        "\n",
        "# Here 7th layer is the DepthwiseConv2D layer\n",
        "for i in range(len(model.layers)):\n",
        "    if i <= 7:\n",
        "        model.layers[i].trainable=False\n",
        "\n",
        "for variable in model.trainable_variables:\n",
        "    print(variable.name)\n",
        "\n",
        "head = model\n",
        "\n",
        "# Optimizer is ignored by the converter! See docs.\n",
        "head.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
        "converter = TFLiteTransferConverter(4,\n",
        "                                    base,\n",
        "                                    heads.KerasModelHead(head),\n",
        "                                    optimizers.SGD(3e-2),\n",
        "                                    train_batch_size=20)\n",
        "\n",
        "converter.convert_and_save('custom_keras_model')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a70514598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a70514598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a6bcd4f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a6bcd4f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a6bc9d6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a6bc9d6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f1a6bcf1ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f1a6bcf1ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a6b463950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a6b463950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Assets written to: base_model/assets\n",
            "pointwise_conv64_1/kernel:0\n",
            "dense/kernel:0\n",
            "dense/bias:0\n",
            "dense_1/kernel:0\n",
            "dense_1/bias:0\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:44: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /tmp/tmp8mmhsz4mtflite-transfer-keras-model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:49: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8mmhsz4mtflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8mmhsz4mtflite-transfer-keras-model/variables/variables\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8mmhsz4mtflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:275: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 9 variables.\n",
            "INFO:tensorflow:Converted 9 variables to const ops.\n",
            "WARNING:tensorflow:Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f1a70d50488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f1a70d50488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a70514158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1a70514158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py:854: UserWarning: Property target_ops is deprecated, please use target_spec.supported_ops instead.\n",
            "  \"target_spec.supported_ops instead.\" % name)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21nToNEBIII3",
        "colab_type": "text"
      },
      "source": [
        "4. Here, we try to convert a BatchNorm Layer to TFLite. However, as we see, it will give an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWGVGbHwfUNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82afe0ca-cef6-410b-a277-281482fdee8f"
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tfltransfer import bases\n",
        "from tfltransfer import heads\n",
        "from tfltransfer import optimizers\n",
        "from tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\n",
        "\n",
        "\"\"\"\n",
        "Get the Base model\n",
        "\"\"\"\n",
        "base = tf.keras.Sequential([tf.keras.layers.InputLayer(input_shape=(224,224,3))])\n",
        "base.save(\"base_model\", save_format=\"tf\")\n",
        "base = bases.SavedModelBase(\"base_model\")\n",
        "\n",
        "\"\"\"\n",
        "BatchNorm Layer\n",
        "\"\"\"\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=(3,3), strides=(1,1), input_shape=(224, 224, 3), padding='same'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "head = model\n",
        "\n",
        "\n",
        "# Optimizer is ignored by the converter! See docs.\n",
        "head.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
        "converter = TFLiteTransferConverter(4,\n",
        "                                    base,\n",
        "                                    heads.KerasModelHead(head),\n",
        "                                    optimizers.SGD(3e-2),\n",
        "                                    train_batch_size=20)\n",
        "\n",
        "converter.convert_and_save('custom_keras_model')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c71a0a488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c71a0a488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c6d1e7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c6d1e7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c6c9978c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c6c9978c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f3c6d1e79d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f3c6d1e79d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c6c963b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c6c963b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Assets written to: base_model/assets\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:44: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /tmp/tmpj9otyd4ktflite-transfer-keras-model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/examples/lite/examples/model_personalization/converter/tfltransfer/heads/keras_model_head.py:49: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpj9otyd4ktflite-transfer-keras-model/variables/variables\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpj9otyd4ktflite-transfer-keras-model/variables/variables\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpj9otyd4ktflite-transfer-keras-model/variables/variables\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:275: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 8 variables.\n",
            "INFO:tensorflow:Converted 8 variables to const ops.\n",
            "WARNING:tensorflow:Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f3c6d1c9d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function KerasModelHead.generate_initial_params.<locals>.model_func at 0x7f3c6d1c9d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c6a748c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c6a748c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._updates\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._updates\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n",
            "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "to_proto not supported in EAGER mode.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0392bf11e2b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                                     train_batch_size=20)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'custom_keras_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/examples/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_converter.py\u001b[0m in \u001b[0;36mconvert_and_save\u001b[0;34m(self, out_model_dir)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/examples/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_converter.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0minitialize_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_initialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mbottleneck_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_bottleneck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mtrain_head_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_train_head_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0minference_model_lite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_inference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mparameter_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_parameter_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_model_lite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/examples/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_converter.py\u001b[0m in \u001b[0;36m_generate_train_head_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       converter = tfv1.lite.TFLiteConverter.from_session(\n\u001b[0;32m--> 140\u001b[0;31m           sess, [bottleneck, labels] + variables, [loss] + gradients)\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_requires_flex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_session\u001b[0;34m(cls, sess, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0mTFLiteConverter\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \"\"\"\n\u001b[0;32m--> 628\u001b[0;31m     \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_freeze_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m     return cls(\n\u001b[1;32m    630\u001b[0m         \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/util.py\u001b[0m in \u001b[0;36mfreeze_graph\u001b[0;34m(sess, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_grappler_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"function\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m   graph_def = run_graph_optimizations(\n\u001b[0;32m--> 238\u001b[0;31m       graph_def, input_tensors, output_tensors, config, graph=sess.graph)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;31m# If ophints are present, just convert them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/util.py\u001b[0m in \u001b[0;36mrun_graph_optimizations\u001b[0;34m(graph_def, input_arrays, output_arrays, config, graph)\u001b[0m\n\u001b[1;32m    194\u001b[0m   \u001b[0mfetch_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_meta_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCollectionDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_arrays\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput_arrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mfetch_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mmeta_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_op\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiiqCsiEP2uR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "e44b3109-cb20-4cb6-8024-6a2ad232f280"
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tfltransfer import bases\n",
        "from tfltransfer import heads\n",
        "from tfltransfer import optimizers\n",
        "from tfltransfer.tflite_transfer_converter import TFLiteTransferConverter\n",
        "\n",
        "\n",
        "# # Functional API\n",
        "# x_in = tf.keras.layers.Input(shape=(224,224,3))\n",
        "# x = layers.Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='valid')(x_in)\n",
        "# x = layers.Activation('relu')(x_in)\n",
        "# x = layers.GlobalAveragePooling2D()(x)\n",
        "# x_out = layers.Dense(4, activation='softmax')(x)\n",
        "# model = tf.keras.Model(inputs=x_in, outputs=x_out)\n",
        "\n",
        "\n",
        "# Sequential API\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=(3,3), strides=(1,1), input_shape=(224,224,3), padding='valid'))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "\n",
        "import tensorflow.compat.v1 as tfv1\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "out_model_dir = 'tmp'\n",
        "shutil.rmtree(out_model_dir)\n",
        "if not os.path.isdir(out_model_dir):\n",
        "  os.makedirs(out_model_dir)\n",
        "\n",
        "tf.keras.experimental.export_saved_model(model, out_model_dir)\n",
        "\n",
        "with tfv1.Session(graph=tf.Graph()) as sess:\n",
        "  metagraph = tfv1.saved_model.load(sess, tags=[tf.saved_model.SERVING], export_dir=out_model_dir)\n",
        "  _eval_signature = metagraph.signature_def.get('serving_default')\n",
        "\n",
        "print(_eval_signature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: tmp/saved_model.pb\n",
            "INFO:tensorflow:Restoring parameters from tmp/variables/variables\n",
            "inputs {\n",
            "  key: \"conv2d_12_input\"\n",
            "  value {\n",
            "    name: \"conv2d_12_input:0\"\n",
            "    dtype: DT_FLOAT\n",
            "    tensor_shape {\n",
            "      dim {\n",
            "        size: -1\n",
            "      }\n",
            "      dim {\n",
            "        size: 224\n",
            "      }\n",
            "      dim {\n",
            "        size: 224\n",
            "      }\n",
            "      dim {\n",
            "        size: 3\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  key: \"dense_12\"\n",
            "  value {\n",
            "    name: \"dense_12/Softmax:0\"\n",
            "    dtype: DT_FLOAT\n",
            "    tensor_shape {\n",
            "      dim {\n",
            "        size: -1\n",
            "      }\n",
            "      dim {\n",
            "        size: 4\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "method_name: \"tensorflow/serving/predict\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}